{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3bf66fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaning Mortality Trend data ###\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "covid = pd.read_csv('covid19mortality.csv')\n",
    "heart = pd.read_csv('heartmortality.csv') #Year for every data observation is 2013\n",
    "stroke = pd.read_csv('strokemortality.csv') #Year for every data observation is 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e0b47e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patas\\AppData\\Local\\Temp/ipykernel_15400/3172309564.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  covid = covid.drop(['Year','Footnote'],1)\n",
      "C:\\Users\\patas\\AppData\\Local\\Temp/ipykernel_15400/3172309564.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  heart = heart.drop(['Year','LocationDesc', 'DataSource','Class','Topic','Data_Value_Unit',\n",
      "C:\\Users\\patas\\AppData\\Local\\Temp/ipykernel_15400/3172309564.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  stroke = stroke.drop(['Year','LocationDesc','DataSource','Class','Topic','Data_Value_Unit','Data_Value_Type',\n"
     ]
    }
   ],
   "source": [
    "#Drop columns that are not necessary for analysis\n",
    "covid = covid.drop(['Year','Footnote'],1)\n",
    "heart = heart.drop(['Year','LocationDesc', 'DataSource','Class','Topic','Data_Value_Unit',\n",
    "                   'Data_Value_Type','Data_Value_Footnote_Symbol', 'StratificationCategory1',\n",
    "                   'StratificationCategory2', 'TopicID', 'LocationID','Location 1','GeographicLevel'], 1)\n",
    "stroke = stroke.drop(['Year','LocationDesc','DataSource','Class','Topic','Data_Value_Unit','Data_Value_Type',\n",
    "                     'StratificationCategory1','Data_Value_Footnote_Symbol'\n",
    "                     ,'StratificationCategory2','TopicID','LocationID','Y_lat','X_lon','GeographicLevel'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f15636ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want data analysis to be easy to process and less time to take, so let's clarify some column values and\n",
    "#create a legend key to shorten the column values to look through the dataset\n",
    "covid = covid.rename(columns = {'Non-Hispanic White':'W', 'Non-Hispanic Black or African American': 'B/AA',\n",
    "                       'Non-Hispanic American Indian or Alaska Native':'AIAN', 'Non-Hispanic Asian':'A',\n",
    "                        'Non-Hispanic Native Hawaiian or Other Pacific Islander': 'NH/OPI',\n",
    "                        'Non Hispanic more than one race': 'MultipleRaces', 'Hispanic or Latino' : 'H/L'})\n",
    "\n",
    "heart = heart.rename(columns = {'Data_Value': 'Deaths per 100,000', 'Data_Value_Footnote': 'Sufficiency?'\n",
    "                               ,'Stratification1': 'Gender', 'Stratification2': 'Race/Ethnicity'})\n",
    "\n",
    "stroke = stroke.rename(columns = {'Data_Value': 'Deaths per 100,000', 'Data_Value_Footnote': 'Sufficiency?'\n",
    "                                 ,'Stratification1': 'Gender','Stratification2': 'Race/Ethnicity'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dcac518f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LocationAbbr  Deaths per 100,000   Gender  \\\n",
      "0               AK               147.4  Overall   \n",
      "1               AK               229.4  Overall   \n",
      "2               AK               255.5  Overall   \n",
      "3               AK               305.5  Overall   \n",
      "5               AK               281.7  Overall   \n",
      "...            ...                 ...      ...   \n",
      "59068           WY               331.9     Male   \n",
      "59069           WY               175.7   Female   \n",
      "59073           WY               462.0  Overall   \n",
      "59074           WY               586.7     Male   \n",
      "59075           WY               351.3   Female   \n",
      "\n",
      "                           Race/Ethnicity  \n",
      "0                                 Overall  \n",
      "1                                 Overall  \n",
      "2                                 Overall  \n",
      "3                                 Overall  \n",
      "5                                 Overall  \n",
      "...                                   ...  \n",
      "59068                            Hispanic  \n",
      "59069                            Hispanic  \n",
      "59073  American Indian and Alaskan Native  \n",
      "59074  American Indian and Alaskan Native  \n",
      "59075  American Indian and Alaskan Native  \n",
      "\n",
      "[34361 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patas\\AppData\\Local\\Temp/ipykernel_15400/2460707862.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  heart = heart.drop('Sufficiency?',1) #All data are now sufficient for data analysis\n",
      "C:\\Users\\patas\\AppData\\Local\\Temp/ipykernel_15400/2460707862.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  stroke = stroke.drop('Sufficiency?',1) #Therefore we have no use for this column\n"
     ]
    }
   ],
   "source": [
    "#heart = heart.drop(heart.index[heart['Sufficiency?'] == 'Insufficient Data'],inplace = True)\n",
    "heart = heart[heart['Sufficiency?'] != 'Insufficient Data']\n",
    "stroke = stroke[stroke['Sufficiency?'] != 'Insufficient Data']\n",
    "\n",
    "heart = heart.drop('Sufficiency?',1) #All data are now sufficient for data analysis\n",
    "stroke = stroke.drop('Sufficiency?',1) #Therefore we have no use for this column\n",
    "print(heart)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
